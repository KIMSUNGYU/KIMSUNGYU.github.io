---
layout: post
title: CS229 Lecture4 정리
use_math: true
---

# CS229 Lec 4 정리   

### Lec 4 요약
Perceptron Learning algorithm, Exponential Familiy, Generalized Linear Models, Softmax Regression, Multiclass Classification 에 대해 정리해보겠습니다.
- - -
__Perceptron Learning algorithm__<br/>
먼저 앞선 강의에서 저희는 $\theta_{j} = \theta_{j} + \alpha(y^i - h_{\theta}(x^i))x_{j}^i$와 같은 learning algorithm을 배웠었습니다.<br/>
이것을 Perceptron learning algorithm이라고 합니다.<br/>
이번 강의에서는 좌표평면위의 그래프를 통해서 어떻게 $\theta^TX$와 $\alpha$가 어떻게 학습을 통해서 개선되는지 눈으로 보면서 좀 더 이해를 쉽게 할 수 있었습니다.<br/>
O,X 2개의 class가 존재하는 그래프에서 예시를 보여주고, 새로운 data가 기존의 학습 방법에 따라 mis-classified되면 기존의 판별 기준을 수정해야 하는데 이것을 직접 선을 그려서 $\theta$와 x에 대한 그래프로 그려서 learning rate를 적용해서 새로 학습하게되면 learning algorithm이 어떻게 개선되는지 직접 눈으로 봐서 그저 되겠구나가 아니라 vector관점으로 납득할 수 있었습니다. ($\theta$가 learning rate를 적용한 x와 더해지면서 개선된 $\theta$가 나오게 됨.)<br/>
하지만 이것을 실제로 잘 사용되지 않는 이유는 Vector 관점에서는 해석이 가능하지만 Probablistic interpretation이 가능하지 않고 XOR Problem 같은 것을 해결하지 못하는 한계가 존재하기 때문입니다.<br/>
- - -
__Exponential Family__<br/>
Generalized Linear Models(GLM)을 공부하기 전에 distribution들을 하나의 형태로 표현해주는 exponential family에 대해 알아보도록 하겠습니다.<br/>
다루는 data 혹은 수행해야하는 task의 종류에 따라서 사용하는 distribution이 달라집니다.
* Real value -> Gaussian 
* Binary -> Bernoulli
* Count -> Poisson 
* $R^2$ -> Gamma, Exponential (양의 정수)
* Distribution -> Beta, Dirichlet <- Mostly show up in Bayesian ML or Bayesian Statistics <br/>

이러한 distribution들을 아래의 식으로 표현해서 나타낼 수 있습니다.<br/>
![image](https://user-images.githubusercontent.com/76681022/213844785-1db4d9fb-b041-4340-8650-a817a88c01ff.png)

먼저 (Bernoulli -> use binary model) 이것을 조작해서 위의 exponential family 형태로 만들 수 있는데 아래의 식을 참고하면 됩니다.<br/>

![image](https://user-images.githubusercontent.com/76681022/213845321-d98b2261-498f-40b1-8286-bd4e62272098.png)

위의 식을 보면 exponential family에 해당하는 값이 아래의 식처럼 구해질 수 있다는 것을 알 수 있습니다.<br/>
![image](https://user-images.githubusercontent.com/76681022/213845331-172edf8e-2aef-417f-889d-00c3b984f174.png)

이제는 Gaussian distribution도 exponential family로 표현해보도록 하겠습니다.<br/>
Gaussian distribution를 계산할 때는 variance = 1로 fix해주고 계산해보겠습니다.<br/>
![image](https://user-images.githubusercontent.com/76681022/213845370-2ed49cdc-dca3-4da9-9da5-c78f113c4ba2.png)
![image](https://user-images.githubusercontent.com/76681022/213845375-b3029ac1-34f2-4850-b086-f94298280e35.png)

Bernoulli와 마찬가지로 Gaussian 또한 exponential family로 나타낼 수 있음을 알 수 있습니다.<br/>

그런데 왜 exponential family를 사용해서 쓸까요?<br/>
그 이유는 exponential family가 mathmatical properties를 가지고 있기 때문입니다.<br/>
.<br/>
1. Exponential family가 natural parameters로 parameterized되면.<br/>
  A. MLE with respect to eta -> concave (위로 볼록한 것).<br/>
  B. Negative Log Likelihood is convex (아래로 볼록한 것).<br/>
2. $E[y;\eta] =  {\partial\over\partial \eta}a(\eta)$.<br/>
3. $Var[y;\eta] = {\partial^2\over\partial eta^2}a(\eta)$.<br/>
=> 적분을 안하고 미분만으로도 평균과 분산을 구할 수 있어서 계산이 간단해지기 때문입니다.<br/>
<br/>
- - -
__Generalized Linear Models(GLM)__<br/>
이제 GLM에 대해 알아보도록 하겠습니다.<br/>
GLM을 만들기위해서는 3가지 단계를 거쳐야 합니다.<br/>
1. (y | x;θ) ∼ ExponentialFamily(η). ( I.e., given x and θ, the distribution of y follows some exponential family distribution, with parameter η).<br/>
2. Given x, our goal is to predict the expected value of T(y) given x. In most of our examples, we will have T(y) = y, so this means we would like the prediction h(x) output by our learned hypothesis h to satisfy h(x) = E[y|x] => $h_{\theta}(x)$ = E[y|x;θ].<br/>
3. The natural parameter η and the inputs x are related linearly: η = $θ^T$ x. (Or, if η is vector-valued, then $\eta_{i} = \theta_{i}^Tx)$<br/>

이렇게 3가지의 단계로 설명하면 추상적이므로 실제 예시를 들어서 설명해보도록 하겠습니다.<br/>
<br/>
x --> $\theta^T x$ --η--> (a, b, T) => training or test time <br/>
(x가 $\theta^T x$에 input으로 들어가면 η가 나오면서 exp family들에 필요한 값이 a, b, T가 구해지게 됩니다.)<br/>
그러면 test time의 경우, $E[y;η] = E[y;\theta^T x] = h_{\theta}(x)$가 됩니다.<br/>
training에서는 max*logP( $y^i;\theta^T x]$<br/>가 나오게 됩니다.<br/>

(여기서 η = canonical link function으로 g(η)을 η에 대해 편미분해주면 나오는 식임을 유의하면 됩니다.)<br/>


Learning Update Rule : $\theta_{j} = \theta_{j} + \alpha (y^i - h_{\theta} (x^i))x_{j}^i$의 $h _{\theta}(x)$에 해당 data에 맞는 distribution 값을 넣고 나온 값을 이용하여 model을 update 해줄 수 있습니다.<br/>
<br/>
model param($\theta$) --$\theta^T x$--> natural param($\eta$) --g--> or <--$g^-1$-- canonical param($\phi, \mu, \sigma, \lambda$)<br/>
                                                
3-parameterizations 으로 정리할 수 있습니다. <br/>
1. Model parameter -> θ
2. Natural parameter -> $\mu$
3. Canonical parameter -> $\phi - Bernoulli, \mu,\sigma - Gaussian, \lambda - Poisson$ <br/>
GLM을 학습하려면 model param인 θ만 학습시켜주면 된다는 것을 유의하면 되겠습니다.<br/>
<br/>

Logistic Regression의 경우, $h_{\theta}(x) = E[y|x; \theta] = \phi$가 됩니다. (Binary classification의 경우는 Bernoulli distribution을 사용하므로)<br/>
강의에서 Regression의 경우 그래프에서 데이터를 0,1을 구분하는 직선이 그어져 있는데 그 data가 위치하는 지점마다 gaussian distribution이 그어지게 되고 그 직선이 mean이 되게 됩니다.(mean들의 지점을 이으면 직선이 된다는 뜻 ,여기서 제가 말하는 직선은 $\theta^T x$의 직선으로 해당 직선을 기준으로 위 아래로 0,1이 구분되어지게 하는 직선입니다.)<br/>
직접 그림으로 보니까 좀 더 이해가 수월했습니다.<br/>

<br/>
강의의 마지막으로는 Soffmax Regression(Cross Entropy minimization)을 non-GLM을 사용해서 multiclass classification을 보여줄 것입니다.<br/>
(k = number of classes, x $\in R^n$,  y를 [${0,1}^k$]로 one-hot vector)<br/>
softmax regression은 θ가 dimension n을 가질 때 k개의 class가 존재하면 NxK matrix로 θ가 class별로 존재하게 됩니다.<br/>
원래는 그림으로 그래프를 그려서 여러 개의 class를 구분할 수 있는 각각의 선을 그리고 그것을 이용해서 구분하는데<br/>
그게 아니라 class별로 $\theta_{class}^T x$의 값을 나타내주면 위에서 그린 그래프의 어디에 위치하는지에 따라서 음~양의 값이 정해지게 되고<br/>
이것을 exponential을 취해주면 0보다 큰 양수의 값이 나오게 됨. = $hat{p}(y)$<br/>
그리고 이것을 normalize해주면 class들의 합이 1이 되고 이것을 다시 p(y)로 바꿔주면 판별한 class만 1이 나오고 나머지는 0이 나오게 됨. = p(y)<br/>
$hat{p}(y)$의 distribution을 p(y)의 distribution으로 바꿔주고 싶다는게 목표인데 이것을 minimize the cross entropy between the two distributions라고 합다.<br/>
<br/>
<br/>
- - -
__Cross Entropy__<br/>
본 강의에서는 cross entropy에 대한 추가 설명이 없고 간단하게 넘어가서 제가 스스로 정리를 더 해보았습니다.<br/>
먼저 entropy의 개념에 대해서 먼저 알아보도록 하겠습니다.<br/>
entropy = 불확실성의 척도입니다.<br/>
entropy가 높다는 것은 정보가 많고, 확률이 낮다는 것을 의미합니다. (예시로 주머니에서 공을 꺼내는 것을 많이 들어서 설명해주었습니다.)<br/>
이제 entropy에 대한 간단한 설명을 마쳤으니 cross entropy에 대한 설명을 해드리겠습니다.<br/>
cross entropy = $H_{p}^q = -\sum_{i=1}^n q(x_{i} log p(x_{i})$ <br/>
cross entropy는 예측 모형이 실제 분포인 q 를 몰라서, 모델링을 하여 q 분포를 예측하고자 하는 것입니다. 예측 모델링을 통해 구한 분포를 p(x)라고 하고 실제 분포인 q를 예측하는 p 분포를 만들었을 때, 이 때 cross-entropy 는 위와 같이 정의됩니다.<br/>
cross entropy는 두 확률 분포의 차이를 구하기 위해서 사용된다고 할 수 있습니다.<br/>
딥러닝에서는 실제 데이터의 확률 분포와, 학습된 모델이 계산한 확률 분포의 차이를 구하는데 사용되는데<br/>
머신러닝에서는 예측 모형에서 훈련 데이터에서는 실제 분포인 q 를 알 수 있기 때문에 cross entropy 를 계산할 수 있습니다.<br/>
즉, 훈련 데이터를 사용한 예측 모형에서 cross-entropy 는 실제 값과 예측값의 차이를 계산하는데 사용할 수 있고 이것이 위의 강의 정리에서 언급한 minimize cross entropy가 두 분포의 차이를 줄이기 위한 우리의 목표라고 언급한 것입니다.<br/>






