---
layout: post
title: CS229 Lecture2 정리
use_math: true
---
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

# CS229 Lec 2 정리 
## __강의를 정리하기 전에.__
공부를 함에 있어서 중요한 것은 선대의 학자들이 정리하고 그렇게 쓰기로 약속한 기호, 문자, 표기법등을 숙지하여 수식을 공부하고 이해하는 것이 중요하다고 생각합니다.<br/>
앞으로 강의를 정리함에 있어 다양한 문자, 기호들이 나오는데 이것을 잘 받아들여서 공부를 하면 좋을 것 같습니다.<br/>


### __Lec 2 요약__
Linear Regression이란 n개의 features를 가진 m개의 training set을 가지고 learning algorithm을 거쳐서 $\hat{y}$ (output = predicted y)을 찾아주는 것입니다.<br/>
cost function $J(\theta)$를 활용하여 predicted y와 실제 data y의 차이를 최소화하도록 할 것입니다.<br/>
cost function $J(\theta)$에서 예측 값과 실제 값의 차이를 줄이기 위해 사용하는 방법이 Gradient Descent 방법인데, Batch Gradient Descent 와 Stochastic Gradient Descet (SGD)를 사용할 수 있습니다.<br/>
이번 강의 정리에서는 위의 내용을 정리하도록 하겠습니다.<br/>
<br/>

### __Linear Regression__
*Machine Learning에서 input X는 대문자, output y는 소문자로 표기하므로 유의하시면 좋겠습니다.*<br/>
먼저 Linear Regression에서 $\theta$는 parameters (weights)라고 하고 X를 y에 mapping 시킬 때 사용됩니다.<br/>

![image](https://user-images.githubusercontent.com/76681022/213342099-327cba06-f26c-4ac5-9b0a-3881669a09a9.png)

(여기서 $\theta_{0}$에 $X_{0}$가 붙지 않은 이유는 $X_{0} = 1$로 dummy feature이기 때문입니다.)<br/>
먼저 hypothesis는 가정이라는 뜻인데, 제 나름대로 추측하기로는 input X 값을 활용해서 우리가 원하는 output y의 값을 구할 것이므로 사용하지 않았나하는 생각입니다.<br/>
Lec 1에서의 예시를 계속 사용해보겠습니다. 방의 개수등 집 값에 영향을 주는 input features를 X라고 하고, 우리가 구하길 원하는 집 값을 output y라고 했을 때, 우리가 구한 예측 값은 $h_{\theta}(X^i)$ = $\hat{y}$가 되는 것입니다.<br/>
m개의 모든 training sample에 대해서 나온 $\hat{y}$ 값은 h(X)가 됩니다.<br/>
위의 수식에서 $\theta_{0,1,2}$만 쓰여진 이유는 예시에서 방의 개수, 집의 넓이 2가지 feature만 사용했기 때문입니다.<br/>

$x \in \mathbb{R}^2$ 라고 표기하고 <br/>
$X = \begin{bmatrix}x_0 \\ x_1 \\ x_2\\ \end{bmatrix}$&emsp;
$\theta = \begin{bmatrix} \theta_{0}\\ \theta_{1} \\ \theta_{2} \\ \end{bmatrix}$가 된다. <br/>

<br/>
모든 training sample의 $h_{\theta}(X^i)$를 구해준 것이 h(x)입니다.
( $\theta$ 와 X가 matrix이므로 $\theta^T$ $x$로 h(x)를 구해줍니다.) 
<br/>

![image](https://user-images.githubusercontent.com/76681022/213342122-7b3d149c-42fd-438e-9375-af3a364d0c34.png)

cost function
![image](https://user-images.githubusercontent.com/76681022/213342140-f98f7701-e565-4448-ac37-d78f6da5a81b.png)

편미
![image](https://user-images.githubusercontent.com/76681022/213342195-996eaac0-a147-4faf-9f05-6a5c68b07065.png)










