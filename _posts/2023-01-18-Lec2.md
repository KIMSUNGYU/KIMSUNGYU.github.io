---
layout: post
title: CS229 Lecture2 정리
use_math: true
---

# CS229 Lec 2 정리 
## __강의를 정리하기 전에.__
공부를 함에 있어서 중요한 것은 선대의 학자들이 정리하고 그렇게 쓰기로 약속한 기호, 문자, 표기법등을 숙지하여 수식을 공부하고 이해하는 것이 중요하다고 생각합니다.<br/>
앞으로 강의를 정리함에 있어 다양한 문자, 기호들이 나오는데 이것을 잘 받아들여서 공부를 하면 좋을 것 같습니다.<br/>


### __Lec 2 요약__
Linear Regression이란 n개의 features를 가진 m개의 training set을 가지고 learning algorithm을 거쳐서 $\hat{y}$ (output = predicted y)을 찾아주는 것입니다.<br/>
cost function $J(\theta)$를 활용하여 predicted $\hat{y}$ 와 실제 data y의 차이를 최소화하도록 할 것입니다.<br/>
cost function $J(\theta)$에서 예측 값과 실제 값의 차이를 줄이기 위해 사용하는 방법이 Gradient Descent 방법인데, Batch Gradient Descent 와 Stochastic Gradient Descet (SGD)를 사용할 수 있습니다.<br/>
이번 강의 정리에서는 위의 내용을 정리하도록 하겠습니다.<br/>
<br/>

### __Linear Regression__
*Machine Learning에서 input X는 대문자, output y는 소문자로 표기하므로 유의하시면 좋겠습니다.*<br/>
먼저 Linear Regression에서 $\theta$는 parameters (weights)라고 하고 X를 y에 mapping 시킬 때 사용됩니다.<br/>

![image](https://user-images.githubusercontent.com/76681022/213342099-327cba06-f26c-4ac5-9b0a-3881669a09a9.png)

![image](https://user-images.githubusercontent.com/76681022/213342122-7b3d149c-42fd-438e-9375-af3a364d0c34.png)

(여기서 $\theta_{0}$에 $X_{0}$가 붙지 않은 이유는 $X_{0} = 1$로 dummy feature이기 때문입니다.)<br/>
먼저 hypothesis는 가정이라는 뜻인데, 제 나름대로 추측하기로는 input X 값을 활용해서 우리가 원하는 output y의 값을 구할 것이므로 사용하지 않았나하는 생각입니다.<br/>
Lec 1에서의 예시를 계속 사용해보겠습니다. 방의 개수등 집 값에 영향을 주는 input features를 X라고 하고, 우리가 구하길 원하는 집 값을 output y라고 했을 때, 우리가 구한 예측 값은 $h_{\theta}(X^i)$ = $\hat{y}$가 되는 것입니다.<br/>
m개의 모든 training sample에 대해서 나온 $\hat{y}$ 값은 h(X)가 됩니다.<br/>
위의 수식에서 $\theta_{0,1,2}$만 쓰여진 이유는 예시에서 방의 개수, 집의 넓이 2가지 feature만 사용했기 때문입니다.<br/>


$x \in \mathbb{R}^2$ 라고 표기하고 <br/>


$X = \begin{bmatrix}x_0 \\ x_1 \\ x_2\\ \end{bmatrix}$&emsp; 

$\theta$ = $\begin{bmatrix} \theta_{0}\\ \theta_{1} \\ \theta_{2} \\ \end{bmatrix}$ 가 됩니다. <br/>
(실제로는 column vector의 형태입니다.)<br/>


위의 식처럼 모든 training sample의 $h_{\theta}(X^i)$를 구해준 것이 h(x)입니다.<br/>

( $\theta$ 와 X가 matrix이므로 $\theta^T$ $x$로 h(x)를 구해줄 수 있니다.) <br/>

<br/>
### __cost function__
<br/>
![image](https://user-images.githubusercontent.com/76681022/213342140-f98f7701-e565-4448-ac37-d78f6da5a81b.png)
<br/>
실제 y 값과 $\hat{y}$ 값의 차이를 줄여서 가장 잘 예측할 수 있도록 해주는 것이 $J(\theta)$ 입니다.<br/>
$J(\theta)$ 에서 뒤의 값을 제곱해주는 이유는 추후 강의에서 설명하도록 하겠습니다.<br/>
이 때 $J(\theta)$ 의 값을 최소화하도록 Gradient Descent 방법을 사용하는데 식은 아래와 같습니다.<br/>

<br/>
![image](https://user-images.githubusercontent.com/76681022/213342195-996eaac0-a147-4faf-9f05-6a5c68b07065.png)
(j = 0,1, ... n) <- n개의 feature를 의미 <br/>

Gradient Descent는 initial weights에서 시작해서 계속해서 학습을 반복해서 최적의 weights를 찾아주는 방법을 의미합니다.<br/>
식에서 $\alpha$는 learning rate라는 값이며, 관습적으로 0.01부터 시작해서 늘리거나 빼주곤 합니다.<br/>
learning rate를 빼주는 이유는 양의 2차 함수의 그래프를 생각했을 때, 함수의 최소가 되는 부분은 가장 아래의 지점이므로 그 지점을 향해서 점점 내려간다는 느낌을 생각하면 됩니다.<br/>
위의 cost function을 편미분해준 결과는 아래의 식처럼 나오게 됩니다.<br/>

<br/>
![image](https://user-images.githubusercontent.com/76681022/213350717-2ad8143d-2784-4ba3-a86e-df81227e2a29.png)

따라서 이 식을 정리해주면 하나의 training sample에 대해 아래의 식처럼 정리할 수 있습니다.<br/>

![image](https://user-images.githubusercontent.com/76681022/213350836-0e83306b-02a1-42ad-9176-8449326aa0c0.png)
<br/>

이것을 모든 m개의 training sample에 대해 적용하게 되면 아래와 같이 정리할 수 있습니다.
![image](https://user-images.githubusercontent.com/76681022/213350956-4345225b-0525-4465-9f75-cff42041d3f7.png)
<br/>
(위의 식처럼 $J(\theta)$ 를 편미분한 것에 j = 0,1,...n 모두를 넣어주는 이유는 $J(\theta)$를 편미분하면 해당 j 값에 해당하는 $\theta$ 와 x만 남아있고 ($\theta$
에 영향을 미치고) 나머지는 사라지게 되므로 편미분한 식에는 모든 j의 값을 넣어주게 되는 것입니다. <br/>
<br/>
<br/>

### __Gradient Descent__<br/>
batch gradient descent, stochastic gradient descent가 존재하는데 위에서 언급한 gradient descent 방법은 batch gradient descent 방법이라고 보면 될 것 같습니다.<br/>
두개의 차이점은 다음 step을 나아갈 때, 얼마만큼의 data-set을 사용하냐의 차이입니다.<br/>
batch gradient descent -> 모든 data-set을 사용하여 다음 step을 계산합니다.<br/>
stochastic gradient descent -> data-set의 일부분을 사용하여 다음 step을 계산합니다.<br/>
<br/>

batch gradient descent의 경우, data-set이 큰 경우 연산량이 많아서 한 step 나아갈 때마다 시간이 오래걸린다는 점과 local minima에 도달하여 global minimum에 도달할 수 없을수도 있습니다.<br/>
하지만 stochastic gradient descent의 경우, noisy하고 random한 path를 가지면서 oscilate할 수 있지만 Avg global minimum으로 향할 수 있습니다.<br/>
또한 step별 연산량이 작아 더 빠르게 global minimum에 도달할 수 있다는 점도 장점입니다.<br/>
<br/>
<br/>

