---
layout: post
title: CS229 Lecture5 정리
use_math: true
---

# CS229 Lec 5 정리   

### Lec 5 요약
* Gaussian Discriminative Analysis (GDA)
* Generative vs Discriminative comparison
* Naive Bayes - ex) spam filter <br/>
이 주제들을 공부해보도록 하겠습니다.<br/>
각 주제들에 대해 간략하게 언급하고 강의에 대해 정리해보도록 하겠습니다.
여태까지 우리가 배운 것은 discriminative learning algorithms입니다.<br/>
Discriminative learning algorithm = Learn p(y|x) or learn $h_{\theta}(x)$ = 0 or 1 directly (x를 y에 바로 mapping함으로써 나오
는 값.)<br/>
Generative learning algorithm = maximize likelihood (이전에 배웠던 separation 해줬던 것들과는 다름)<br/>
Generative learning algorithm = Learn p(x|y) = class에 주어진 feature들이 어떻게 생겼는지 학습하는 것입니다.(종양을 예시로 드
는데, 만약에 악성 종양이면 그 종양의 특성은 어떤 것이 주어져있는지 학습한다는 뜻.)<br/>
Bayes rule <br/>
이것을 적용하면 p(y=1|x) = { p(x|y=1)p(y=1) } / p(x)로 계산할 수 있습니다.<br/>
ex) p(x) = p(x|y=1)p(y=1) + p(x|y=0)p(y=0)
- - -

### Gaussian Discriminative Analysis (GDA)
• Suppose $x \in R^n$ (drop $x_{0} = 1$ convention) 이렇게 해주고 시작할 것입니다.
이렇게 해주면 x가 0~n까지 있어도 $x_{0} = 1$이므로 x는 1~n 즉, n개 존재하는 것입니다.
• Assume p(x|y) is Gaussian -> 종양을 예시로 들면, 악성/양성 종양 모두 가우시안 분포를 가진
다는 뜻입니다.
1번 식 적어줌. (Multivariate Gaussian Density Function에 대한 설명)
(아마 다들 식에 대해서 낯설고 아직 어색할텐데 많이 쓰다보면 익숙해질 것이고, 익숙해지는게 좋을
것 같다고 하셔서 식을 눈에 익혀야 겠다는 생각이 들었습니다.)
2개의 parameter를 가지고 있음. ($\mu, \sigma$)
~~~ Multi GDF에 대해 그림 가지고 설명~~~
